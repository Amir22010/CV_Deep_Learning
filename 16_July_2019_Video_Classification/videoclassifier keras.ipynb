{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/data/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":40,"outputs":[{"output_type":"stream","text":"['hockey', 'kabaddi', 'weight_lifting', 'table_tennis', 'cricket', 'ice_hockey', 'formula1', 'shooting', 'tennis', 'swimming', 'models', 'chess', 'football', 'wwe', 'motogp', 'boxing', 'gymnastics', 'volleyball', 'wrestling', 'badminton', 'fencing', 'baseball', 'basketball']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import matplotlib\nmatplotlib.use(\"Agg\")\n# import the necessary packages\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers.pooling import AveragePooling2D\nfrom keras.applications import ResNet50\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dense\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.optimizers import SGD\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport argparse\nimport pickle\nimport cv2\nimport os","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize the set of labels from the spots activity dataset we are\n# going to train our network on\nLABELS = [\n 'cricket',\n 'formula1',\n 'tennis']\nLABELS","execution_count":42,"outputs":[{"output_type":"execute_result","execution_count":42,"data":{"text/plain":"['cricket', 'formula1', 'tennis']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grab the list of images in our dataset directory, then initialize\n# the list of data (i.e., images) and class images\nprint(\"[INFO] loading images...\")\nimagePaths = list(paths.list_images(\"../input/data/\"))","execution_count":43,"outputs":[{"output_type":"stream","text":"[INFO] loading images...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\nlabels = []","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loop over the image paths\nfor imagePath in imagePaths:\n\t# extract the class label from the filename\n\tlabel = imagePath.split(os.path.sep)[-2]\n\n\t# if the label of the current image is not part of of the labels\n\t# are interested in, then ignore the image\n\tif label not in LABELS:\n\t\tcontinue\n\n\t# load the image, convert it to RGB channel ordering, and resize\n\t# it to be a fixed 224x224 pixels, ignoring aspect ratio\n\timage = cv2.imread(imagePath)\n\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\timage = cv2.resize(image, (224, 224))\n\n\t# update the data and labels lists, respectively\n\tdata.append(image)\n\tlabels.append(label)","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(labels)","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"2055"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert the data and labels to NumPy arrays\ndata = np.array(data)\nlabels = np.array(labels)\n# perform one-hot encoding on the labels\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)","execution_count":47,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# partition the data into training and testing splits using 75% of\n# the data for training and the remaining 25% for testing\n(trainX, testX, trainY, testY) = train_test_split(data, labels,\n\ttest_size=0.25, stratify=labels, random_state=42)\n\n# initialize the training data augmentation object\ntrainAug = ImageDataGenerator(\n\trotation_range=30,\n\tzoom_range=0.15,\n\twidth_shift_range=0.2,\n\theight_shift_range=0.2,\n\tshear_range=0.15,\n\thorizontal_flip=True,\n\tfill_mode=\"nearest\")","execution_count":50,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize the validation/testing data augmentation object (which\n# we'll be adding mean subtraction to)\nvalAug = ImageDataGenerator()\n\n# define the ImageNet mean subtraction (in RGB order) and set the\n# the mean subtraction value for each of the data augmentation\n# objects\nmean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\ntrainAug.mean = mean\nvalAug.mean = mean\n\n# load the ResNet-50 network, ensuring the head FC layer sets are left\n# off\nbaseModel = ResNet50(weights=\"imagenet\", include_top=False,\n\tinput_tensor=Input(shape=(224, 224, 3)))","execution_count":51,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# construct the head of the model that will be placed on top of the\n# the base model\nheadModel = baseModel.output\nheadModel = AveragePooling2D(pool_size=(7, 7))(headModel)\nheadModel = Flatten(name=\"flatten\")(headModel)\nheadModel = Dense(512, activation=\"relu\")(headModel)\nheadModel = Dropout(0.5)(headModel)\nheadModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n\n# place the head FC model on top of the base model (this will become\n# the actual model we will train)\nmodel = Model(inputs=baseModel.input, outputs=headModel)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loop over all layers in the base model and freeze them so they will\n# *not* be updated during the training process\nfor layer in baseModel.layers:\n\tlayer.trainable = False\n\n# compile our model (this needs to be done after our setting our\n# layers to being non-trainable)\nprint(\"[INFO] compiling model...\")\nopt = SGD(lr=1e-4, momentum=0.9, decay=1e-4 / 50)\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n\tmetrics=[\"accuracy\"])","execution_count":53,"outputs":[{"output_type":"stream","text":"[INFO] compiling model...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train the head of the network for a few epochs (all other layers\n# are frozen) -- this will allow the new FC layers to start to become\n# initialized with actual \"learned\" values versus pure random\nprint(\"[INFO] training head...\")\nH = model.fit_generator(\n\ttrainAug.flow(trainX, trainY, batch_size=32),\n\tsteps_per_epoch=len(trainX) // 32,\n\tvalidation_data=valAug.flow(testX, testY),\n\tvalidation_steps=len(testX) // 32,\n\tepochs=50)","execution_count":54,"outputs":[{"output_type":"stream","text":"[INFO] training head...\nEpoch 1/50\n48/48 [==============================] - 24s 502ms/step - loss: 1.2062 - acc: 0.4232 - val_loss: 0.8681 - val_acc: 0.5879\nEpoch 2/50\n48/48 [==============================] - 17s 360ms/step - loss: 0.9269 - acc: 0.5702 - val_loss: 0.6219 - val_acc: 0.7469\nEpoch 3/50\n48/48 [==============================] - 18s 383ms/step - loss: 0.7525 - acc: 0.6809 - val_loss: 0.4843 - val_acc: 0.8320\nEpoch 4/50\n48/48 [==============================] - 18s 383ms/step - loss: 0.6466 - acc: 0.7321 - val_loss: 0.4251 - val_acc: 0.8838\nEpoch 5/50\n48/48 [==============================] - 18s 380ms/step - loss: 0.5498 - acc: 0.7836 - val_loss: 0.3729 - val_acc: 0.8963\nEpoch 6/50\n48/48 [==============================] - 18s 378ms/step - loss: 0.5154 - acc: 0.7999 - val_loss: 0.3421 - val_acc: 0.9066\nEpoch 7/50\n48/48 [==============================] - 18s 383ms/step - loss: 0.4699 - acc: 0.8300 - val_loss: 0.2967 - val_acc: 0.9253\nEpoch 8/50\n48/48 [==============================] - 18s 382ms/step - loss: 0.4439 - acc: 0.8334 - val_loss: 0.3007 - val_acc: 0.9232\nEpoch 9/50\n48/48 [==============================] - 18s 382ms/step - loss: 0.4069 - acc: 0.8487 - val_loss: 0.2562 - val_acc: 0.9274\nEpoch 10/50\n48/48 [==============================] - 18s 381ms/step - loss: 0.3929 - acc: 0.8580 - val_loss: 0.2455 - val_acc: 0.9315\nEpoch 11/50\n48/48 [==============================] - 18s 380ms/step - loss: 0.3733 - acc: 0.8643 - val_loss: 0.2543 - val_acc: 0.9295\nEpoch 12/50\n48/48 [==============================] - 18s 383ms/step - loss: 0.3813 - acc: 0.8676 - val_loss: 0.2482 - val_acc: 0.9274\nEpoch 13/50\n48/48 [==============================] - 19s 396ms/step - loss: 0.3595 - acc: 0.8689 - val_loss: 0.2508 - val_acc: 0.9315\nEpoch 14/50\n48/48 [==============================] - 18s 383ms/step - loss: 0.3548 - acc: 0.8722 - val_loss: 0.2345 - val_acc: 0.9398\nEpoch 15/50\n48/48 [==============================] - 18s 382ms/step - loss: 0.3176 - acc: 0.8938 - val_loss: 0.2045 - val_acc: 0.9357\nEpoch 16/50\n48/48 [==============================] - 18s 382ms/step - loss: 0.3174 - acc: 0.8839 - val_loss: 0.2240 - val_acc: 0.9357\nEpoch 17/50\n48/48 [==============================] - 18s 379ms/step - loss: 0.3112 - acc: 0.8884 - val_loss: 0.2136 - val_acc: 0.9398\nEpoch 18/50\n48/48 [==============================] - 18s 379ms/step - loss: 0.2986 - acc: 0.8964 - val_loss: 0.2141 - val_acc: 0.9375\nEpoch 19/50\n48/48 [==============================] - 18s 378ms/step - loss: 0.3078 - acc: 0.8926 - val_loss: 0.2146 - val_acc: 0.9357\nEpoch 20/50\n48/48 [==============================] - 18s 382ms/step - loss: 0.3009 - acc: 0.8932 - val_loss: 0.1930 - val_acc: 0.9481\nEpoch 21/50\n48/48 [==============================] - 18s 378ms/step - loss: 0.2799 - acc: 0.9082 - val_loss: 0.2130 - val_acc: 0.9336\nEpoch 22/50\n48/48 [==============================] - 18s 382ms/step - loss: 0.2792 - acc: 0.9004 - val_loss: 0.2051 - val_acc: 0.9378\nEpoch 23/50\n48/48 [==============================] - 18s 375ms/step - loss: 0.2682 - acc: 0.9075 - val_loss: 0.1913 - val_acc: 0.9461\nEpoch 24/50\n48/48 [==============================] - 18s 378ms/step - loss: 0.2529 - acc: 0.9062 - val_loss: 0.1727 - val_acc: 0.9564\nEpoch 25/50\n48/48 [==============================] - 18s 374ms/step - loss: 0.2557 - acc: 0.9067 - val_loss: 0.1955 - val_acc: 0.9440\nEpoch 26/50\n48/48 [==============================] - 18s 376ms/step - loss: 0.2408 - acc: 0.9143 - val_loss: 0.1864 - val_acc: 0.9440\nEpoch 27/50\n48/48 [==============================] - 18s 377ms/step - loss: 0.2668 - acc: 0.8993 - val_loss: 0.2065 - val_acc: 0.9336\nEpoch 28/50\n48/48 [==============================] - 18s 377ms/step - loss: 0.2522 - acc: 0.9114 - val_loss: 0.1618 - val_acc: 0.9585\nEpoch 29/50\n48/48 [==============================] - 18s 377ms/step - loss: 0.2491 - acc: 0.9019 - val_loss: 0.2382 - val_acc: 0.9232\nEpoch 30/50\n48/48 [==============================] - 19s 397ms/step - loss: 0.2679 - acc: 0.8956 - val_loss: 0.1278 - val_acc: 0.9647\nEpoch 31/50\n48/48 [==============================] - 18s 376ms/step - loss: 0.2368 - acc: 0.9169 - val_loss: 0.2308 - val_acc: 0.9315\nEpoch 32/50\n48/48 [==============================] - 18s 381ms/step - loss: 0.2361 - acc: 0.9127 - val_loss: 0.1741 - val_acc: 0.9461\nEpoch 33/50\n48/48 [==============================] - 18s 382ms/step - loss: 0.2204 - acc: 0.9153 - val_loss: 0.1639 - val_acc: 0.9544\nEpoch 34/50\n48/48 [==============================] - 18s 381ms/step - loss: 0.2407 - acc: 0.9132 - val_loss: 0.1787 - val_acc: 0.9461\nEpoch 35/50\n48/48 [==============================] - 19s 387ms/step - loss: 0.2391 - acc: 0.9151 - val_loss: 0.1803 - val_acc: 0.9473\nEpoch 36/50\n48/48 [==============================] - 18s 379ms/step - loss: 0.2190 - acc: 0.9284 - val_loss: 0.1772 - val_acc: 0.9461\nEpoch 37/50\n48/48 [==============================] - 18s 381ms/step - loss: 0.2235 - acc: 0.9160 - val_loss: 0.1717 - val_acc: 0.9461\nEpoch 38/50\n48/48 [==============================] - 18s 377ms/step - loss: 0.2181 - acc: 0.9251 - val_loss: 0.1676 - val_acc: 0.9461\nEpoch 39/50\n48/48 [==============================] - 18s 381ms/step - loss: 0.2245 - acc: 0.9230 - val_loss: 0.2054 - val_acc: 0.9378\nEpoch 40/50\n48/48 [==============================] - 18s 384ms/step - loss: 0.2011 - acc: 0.9258 - val_loss: 0.1533 - val_acc: 0.9606\nEpoch 41/50\n48/48 [==============================] - 18s 380ms/step - loss: 0.2185 - acc: 0.9284 - val_loss: 0.1521 - val_acc: 0.9523\nEpoch 42/50\n48/48 [==============================] - 18s 378ms/step - loss: 0.2178 - acc: 0.9301 - val_loss: 0.1603 - val_acc: 0.9481\nEpoch 43/50\n48/48 [==============================] - 18s 381ms/step - loss: 0.1909 - acc: 0.9362 - val_loss: 0.1671 - val_acc: 0.9481\nEpoch 44/50\n48/48 [==============================] - 18s 380ms/step - loss: 0.2142 - acc: 0.9197 - val_loss: 0.1686 - val_acc: 0.9440\nEpoch 45/50\n48/48 [==============================] - 18s 379ms/step - loss: 0.2154 - acc: 0.9230 - val_loss: 0.1909 - val_acc: 0.9419\nEpoch 46/50\n48/48 [==============================] - 19s 391ms/step - loss: 0.2023 - acc: 0.9225 - val_loss: 0.1516 - val_acc: 0.9419\nEpoch 47/50\n48/48 [==============================] - 18s 379ms/step - loss: 0.2028 - acc: 0.9284 - val_loss: 0.1595 - val_acc: 0.9564\nEpoch 48/50\n48/48 [==============================] - 18s 377ms/step - loss: 0.1897 - acc: 0.9381 - val_loss: 0.1826 - val_acc: 0.9378\nEpoch 49/50\n48/48 [==============================] - 18s 379ms/step - loss: 0.1906 - acc: 0.9360 - val_loss: 0.1490 - val_acc: 0.9502\nEpoch 50/50\n48/48 [==============================] - 18s 382ms/step - loss: 0.1966 - acc: 0.9290 - val_loss: 0.1662 - val_acc: 0.9419\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate the network\nprint(\"[INFO] evaluating network...\")\npredictions = model.predict(testX, batch_size=32)\nprint(classification_report(testY.argmax(axis=1),\n\tpredictions.argmax(axis=1), target_names=lb.classes_))","execution_count":55,"outputs":[{"output_type":"stream","text":"[INFO] evaluating network...\n              precision    recall  f1-score   support\n\n     cricket       0.90      0.96      0.93       166\n    formula1       0.96      0.96      0.96       169\n      tennis       0.97      0.91      0.94       179\n\n    accuracy                           0.94       514\n   macro avg       0.94      0.94      0.94       514\nweighted avg       0.94      0.94      0.94       514\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot the training loss and accuracy\nN = 50\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy on Dataset\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"<matplotlib.legend.Legend at 0x7fb12232cba8>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.savefig('plot.png')","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href='plot.png'>image</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# serialize the model to disk\nprint(\"[INFO] serializing network...\")\nmodel.save('activity.model')","execution_count":62,"outputs":[{"output_type":"stream","text":"[INFO] serializing network...\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"<a href='activity.model'>image</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# serialize the label binarizer to disk model/lb.pickle\nf = open('lb.pickle', \"wb\")\nf.write(pickle.dumps(lb))\nf.close()","execution_count":63,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href='lb.pickle'>pickle</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}